{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvfY_l2zxpqQ",
        "outputId": "fad71269-303f-46f9-c766-4fa1a1693ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary data for tokenization\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('french'))\n",
        "stop_words.update(['@', '#', '€','!','rt',':','a'])\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86eofbD_xpqU",
        "outputId": "3e073524-c532-48fd-fbe6-2138c97ee10b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df_g = pd.read_csv(\"/content/drive/MyDrive/projet/Tweet2.csv\", on_bad_lines='skip', sep=';')\n",
        "df_g = df_g[ 'data__text']\n",
        "df_g = df_g.dropna()\n",
        "\n",
        "df_d = pd.read_csv(\"/content/drive/MyDrive/projet/Tweet1.csv\", on_bad_lines='skip',sep=';')\n",
        "df_d = df_d[ 'data__text']\n",
        "df_d = df_d.dropna()\n",
        "\n",
        "G_train, G_test  = train_test_split(df_g, test_size=0.99, random_state=42)\n",
        "D_train, D_test = train_test_split(df_d, test_size=0.99, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yySdbSgxpqU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Optimisation de la fonction `remove_stopwords`\n",
        "def remove_stopwords(text, stop_words):\n",
        "    return [word.lower() for word in word_tokenize(text) if word.lower() not in stop_words]\n",
        "\n",
        "# Optimisation de la fonction `remplir`\n",
        "def remplir(counter, words):\n",
        "    for word in words:\n",
        "        counter[word] = counter.get(word, 0) + 1\n",
        "\n",
        "#remplie les listes / dico pour la vectorisation\n",
        "def remplir_dico(dataset,dico_g,dico_local,liste_trie):\n",
        "    for sentence in dataset:\n",
        "        new=remove_stopwords(sentence,stop_words)\n",
        "        remplir(dico_local,new)\n",
        "        remplir(dico_g,new)\n",
        "        liste_trie.append(new)\n",
        "\n",
        "# Préparation des dictionnaires\n",
        "dictio = {}\n",
        "dictio_g = {}\n",
        "dictio_g_test = {}\n",
        "dictio_d = {}\n",
        "dictio_d_test = {}\n",
        "add_g = []\n",
        "add_g_test=[]\n",
        "add_d = []\n",
        "add_d_test=[]\n",
        "\n",
        "# Traitement des phrases\n",
        "remplir_dico(G_train,dictio,dictio_g,add_g)\n",
        "remplir_dico(G_test,dictio,dictio_g_test,add_g_test)\n",
        "remplir_dico(D_train,dictio,dictio_d,add_d)\n",
        "remplir_dico(D_test,dictio,dictio_d_test,add_d_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab4KCOfgxpqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0f057b-440b-4b0d-b37e-1e6064a2b070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5738\n",
            "  (0, 0)\t7\n",
            "  (0, 1)\t71\n",
            "  (0, 2)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 8)\t2\n",
            "  (0, 9)\t1\n",
            "  (0, 10)\t56\n",
            "  (0, 11)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 13)\t2\n",
            "  (0, 14)\t1\n",
            "  (0, 15)\t1\n",
            "  (0, 16)\t2\n",
            "  (0, 17)\t2\n",
            "  (0, 18)\t1\n",
            "  (0, 19)\t1\n",
            "  (0, 20)\t1\n",
            "  (0, 21)\t5\n",
            "  (0, 22)\t4\n",
            "  (0, 23)\t1\n",
            "  (0, 24)\t1\n",
            "  :\t:\n",
            "  (172, 99)\t1\n",
            "  (172, 139)\t3\n",
            "  (172, 181)\t21\n",
            "  (172, 186)\t21\n",
            "  (172, 404)\t2\n",
            "  (172, 1008)\t3\n",
            "  (172, 1062)\t2\n",
            "  (172, 4887)\t1\n",
            "  (172, 6043)\t1\n",
            "  (172, 6776)\t2\n",
            "  (172, 7322)\t1\n",
            "  (172, 9383)\t2\n",
            "  (172, 10045)\t1\n",
            "  (172, 11212)\t1\n",
            "  (172, 11353)\t1\n",
            "  (172, 14134)\t1\n",
            "  (172, 15118)\t1\n",
            "  (172, 16779)\t1\n",
            "  (172, 21203)\t1\n",
            "  (172, 21204)\t1\n",
            "  (172, 21205)\t1\n",
            "  (172, 21206)\t1\n",
            "  (172, 21207)\t1\n",
            "  (172, 21208)\t1\n",
            "  (172, 21209)\t1\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "#fonction de passage dans l'espace\n",
        "def faire_matrice (matrice,liste_texte,dico,index,start):\n",
        "    for i,sentence in enumerate(liste_texte):\n",
        "        for word in sentence:\n",
        "            matrice[start+i,index[word]]=dico[word]\n",
        "\n",
        "# Initialisation de la matrice\n",
        "l = len(dictio)\n",
        "l1 = len(G_train)  # Nombre de phrases dans G_train\n",
        "l1_test = len(G_test)\n",
        "print(l1_test)\n",
        "l2 = len(D_train)  # Nombre de phrases dans D_train\n",
        "l2_test=len(D_test)\n",
        "\n",
        "# Construction de la matrice pour G_train\n",
        "word_to_index = {word: i for i, word in enumerate(dictio)}  # Dictionnaire mot -> index\n",
        "#print(word_to_index['j'])\n",
        "#print(dictio['j'])\n",
        "#print(word_to_index['j'])\n",
        "matrice_A = np.zeros((l1 + l2, l), dtype=np.int16)\n",
        "faire_matrice(matrice_A,add_g,dictio_g,word_to_index,0)\n",
        "faire_matrice(matrice_A,add_d,dictio_d,word_to_index,l1)\n",
        "\n",
        "matrice_A_prime = np.zeros((l1_test + l2_test, l), dtype=np.int16)\n",
        "faire_matrice(matrice_A_prime,add_g_test,dictio_g_test,word_to_index,0)\n",
        "faire_matrice(matrice_A_prime,add_d_test,dictio_d_test,word_to_index,l1_test)\n",
        "\n",
        "sparse_matrice_A = csr_matrix(matrice_A)\n",
        "sparse_matrice_A_prime = csr_matrix(matrice_A_prime)\n",
        "print(sparse_matrice_A)\n",
        "#print(sparse_matrice_A.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tk61W8MxpqV"
      },
      "outputs": [],
      "source": [
        "#Y = np.hstack((np.ones(l1), np.zeros(l2)))  # Labels (1: positif, 0: négatif)\n",
        "#model = LogisticRegression()\n",
        "#model.fit(matrice_A, y)\n",
        "#coefficients = np.linalg.lstsq(matrice_A, Y, rcond=None)[0]\n",
        "\n",
        "# Afficher les résultats\n",
        "#print(\"Matrice des coefficients :\\n\", coefficients)\n",
        "\n",
        "\n",
        "\n",
        "###############################################################\n",
        "matrice_g=np.zeros(l)\n",
        "matrice_d=np.zeros(l)\n",
        "\n",
        "for i,clef in enumerate(dictio) :\n",
        "    if clef in dictio_g:\n",
        "        matrice_g[i]=dictio_g[clef]/dictio[clef]\n",
        "    if clef in dictio_d:\n",
        "        matrice_d[i]=dictio_d[clef]/dictio[clef]\n",
        "\n",
        "l1_test = l1_test+0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZuP28mZxpqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b5829e-1929-47b1-da72-8765de37db9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrice des coefficients :\n",
            " [-0.03886026  0.00389625  0.01863329 ...  0.          0.\n",
            "  0.        ]\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse.linalg import lsqr\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "\n",
        "#matrice_A_normalized = scaler.fit_transform(sparse_matrice_A)\n",
        "scaler = MaxAbsScaler()\n",
        "matrice_A_normalized = scaler.fit_transform(sparse_matrice_A)\n",
        "# Entraînement\n",
        "Y = np.hstack((np.ones(l1), np.zeros(l2)))  # Labels (1: positif, 0: négatif)\n",
        "coefficients = lsqr(matrice_A_normalized, Y)[0]\n",
        "\n",
        "# Résultats des coefficients\n",
        "print(\"Matrice des coefficients :\\n\", coefficients)\n",
        "l1_test = l1_test+0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1_test = l1_test+0\n",
        "import numpy as np\n",
        "# Fonction pour arrondir\n",
        "def arrondir(colonne):\n",
        "    return (colonne >= 0.5).astype(int)\n",
        "\n",
        "# Test\n",
        "\n",
        "Y_test = np.hstack((np.ones(l1_test), np.zeros(l2_test)))  # Labels (1: positif, 0: négatif)\n",
        "Y_pred = sparse_matrice_A_prime @ coefficients  # Utilise l'opérateur @\n",
        "Y_pred=Y_pred.flatten()\n",
        "#print(\"La colonne Y est :\", Y_test)\n",
        "#print(\"La colonne Y_pred est :\", Y_pred)\n",
        "Y_pred = arrondir(Y_pred)\n",
        "\n",
        "# Validation\n",
        "validation = Y_test - Y_pred\n",
        "good = np.sum(validation == 0)\n",
        "not_good = np.sum(validation != 0)\n",
        "\n",
        "print(\"Nb de bons résultats :\", good, \"nb de mauvais :\", not_good, \"sur :\", len(validation))\n",
        "print(\"ratio =\",good/len(validation))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtzxPYPLSRQN",
        "outputId": "8f269e37-24b7-4a03-d91b-50e6829a033c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nb de bons résultats : 6400 nb de mauvais : 10869 sur : 17269\n",
            "ratio = 0.3706062887254618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcFJDgmpxpqV",
        "outputId": "8c113c34-cfff-472f-b28a-4b5277bdf911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0894979819ed>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mY_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrondir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrice_A_prime\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"La colonne Y est :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"La colonne Y_pred est :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0894979819ed>\u001b[0m in \u001b[0;36marrondir\u001b[0;34m(colonne)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcolonne_bis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolonne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolonne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcolonne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mcolonne_bis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def arrondir(colonne):\n",
        "    colonne_bis=np.zeros(len(colonne))\n",
        "    for i in range (len(colonne)):\n",
        "        if colonne[i]<0.5 :\n",
        "            colonne_bis[i]=0\n",
        "        else :\n",
        "            colonne_bis[i]=1\n",
        "    return(colonne_bis)\n",
        "\n",
        "Y_test = np.hstack((np.ones(l1_test), np.zeros(l2_test)))\n",
        "\n",
        "Y_pred=arrondir(matrice_A_prime*coefficients)\n",
        "print(\"La colonne Y est :\", Y_test)\n",
        "print(\"La colonne Y_pred est :\", Y_pred)\n",
        "validation=Y_test-Y_pred\n",
        "\n",
        "good,not_good=0,0\n",
        "for element in validation:\n",
        "    if element==0:\n",
        "        good+=1\n",
        "    elif element==1:\n",
        "        not_good+=1\n",
        "\n",
        "print(\"Nb de bon résultat :\",good,\"nb de mauvais :\",not_good,\"sur :\",len(validation))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}